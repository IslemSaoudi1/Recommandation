{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3695aeb3-a6c1-4229-b1ff-e035608e23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pyodbc\n",
    "import configparser\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class CVAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "    def load_yolo_model(self, model_path):\n",
    "        self.model = YOLO(model_path)\n",
    "\n",
    "    def get_predictions(self, image_path, confidence):\n",
    "        img = cv2.imread(image_path)\n",
    "        results = self.model.predict(source=img, conf=confidence)\n",
    "        return results\n",
    "    \n",
    "    def extract_values_from_image(self, img_path, save_path, name, bboxes, probs, names):\n",
    "        img = cv2.imread(img_path)\n",
    "        img2 = img.copy()\n",
    "        class_names = {\n",
    "            0: 'profile',\n",
    "            1: 'competance',\n",
    "            2: 'experience_professionnelle',\n",
    "            3: 'formation',\n",
    "            4: 'langues',\n",
    "            5: 'centre',\n",
    "            6: 'Contact'\n",
    "        }\n",
    "        dicts = {0: {}, 1: {}, 2: {}, 3: {}, 4: {}, 5: {}, 6: {}}\n",
    "        df = pd.DataFrame(columns=['profile', 'competance', 'experience_professionnelle', 'formation', 'langues', 'centre', 'Contact'])\n",
    "\n",
    "        for box, prob, index in zip(bboxes, probs.tolist(), names):\n",
    "            class_dict = dicts[int(index)]\n",
    "            class_dict[prob] = box\n",
    "\n",
    "        for index, class_dict in dicts.items():\n",
    "            if len(class_dict) != 0:\n",
    "                max_prob = max(class_dict.keys())\n",
    "                box = class_dict[max_prob]\n",
    "                x1, y1, x2, y2 = box\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                cropped_image = img2[y1:y2, x1:x2]\n",
    "                folder_path = class_names[index]\n",
    "                if not os.path.exists(os.path.join(save_path, folder_path)):\n",
    "                    os.makedirs(os.path.join(save_path, folder_path))\n",
    "                file_path = os.path.join(save_path, folder_path, f\"{name.split('.')[0]}-{index}.jpg\")\n",
    "                cv2.imwrite(file_path, cropped_image)\n",
    "                print(file_path)\n",
    "                text = pytesseract.image_to_string(cropped_image)\n",
    "                df.at[0, folder_path] = text if text else None\n",
    "\n",
    "        df.to_csv('my_dataframe.csv', index=False)\n",
    "        return df\n",
    "    def clean_and_sort_dataframe(self, df):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df = df.apply(lambda x: x.astype(str).str.lower().str.strip() if x.dtype == \"object\" else x)\n",
    "        df = df.replace({'\\n': ' ', '\\r': ' '}, regex=True)\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == \"object\":\n",
    "                df[col] = df[col].sort_values()\n",
    "        print(df)\n",
    "        return(df)\n",
    "    def extract_languages_from_dataframe(self, df, language_keywords):\n",
    "        for index, row in df.iterrows():\n",
    "            text = row['langues']\n",
    "            languages = re.findall(r\"\\b([A-Za-zéèëêàâîïôùûü]+)\\b\", text)\n",
    "            normalized_languages = []\n",
    "            for language in languages:\n",
    "                for keyword in language_keywords:\n",
    "                    if keyword.lower() in language.lower():\n",
    "                        normalized_languages.append(keyword)\n",
    "            df.at[index, 'langues'] = ', '.join(normalized_languages) if normalized_languages else None\n",
    "        print(df)\n",
    "    def extract_contact_info(self, df):\n",
    "        # Définition des expressions régulières\n",
    "        phone_regex = r\"\\b\\d{8}\\b\"\n",
    "        email_regex = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\"\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            # Texte d'origine dans df['Contact']\n",
    "            text = row['Contact']\n",
    "            # Extraction du numéro de téléphone\n",
    "            phone_number = re.search(phone_regex, text)\n",
    "            phone_number = phone_number.group() if phone_number else \"\"\n",
    "            df.at[index, 'phone number'] = phone_number\n",
    "\n",
    "            # Extraction de l'email\n",
    "            email = re.search(email_regex, text)\n",
    "            email = email.group() if email else \"\"\n",
    "            df.at[index, 'email'] = email\n",
    "\n",
    "            # Extraction du profil LinkedIn\n",
    "            linkedin_profile = \"\"\n",
    "            start_index = text.find(\"linkedin.com/in/\")\n",
    "            if start_index != -1:\n",
    "                end_index = text.find(\" \", start_index)\n",
    "                if end_index == -1:\n",
    "                    end_index = len(text)\n",
    "                linkedin_profile = text[start_index:end_index]\n",
    "            df.at[index, 'linkedin'] = linkedin_profile\n",
    "        return df\n",
    "    def extract_profile(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        profile = \"\"\n",
    "        for sent in doc.sents:\n",
    "            if \"actuellement\" in sent.text.lower():\n",
    "                profile = sent.text\n",
    "                break\n",
    "        return profile\n",
    "\n",
    "    def apply_extraction(self, df):\n",
    "        df[\"extracted_profile\"] = df[\"profile\"].apply(self.extract_profile)\n",
    "        return df\n",
    "    def replace_empty_with_none(self,df):\n",
    "        # Iterate over each column in the DataFrame\n",
    "        for column in df.columns:\n",
    "            # Check if the column has empty values\n",
    "            if df[column].empty or df[column].dtype == None:\n",
    "                # Replace empty values with None\n",
    "                df[column] = df[column].replace(np.nan, None)\n",
    "        return df\n",
    "    def replace(self, df):\n",
    "        new_df = replace_empty_with_none(df)\n",
    "        return new_df\n",
    "    def save_in_database(self, df):\n",
    "        # Load the config file\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read('../../config.ini')\n",
    "        cnxn_table = (\n",
    "            \"Driver={\"+config['Database']['Driver']+\"};\"\n",
    "            \"Server=\"+config['Database']['Server']+\";\"\n",
    "            \"Database=\"+config['Database']['Database']+\";\"\n",
    "            \"Trusted_Connection=\"+config['Database']['Trusted_Connection']+\";\")\n",
    "        print(cnxn_table)\n",
    "        # Establish a database connection\n",
    "        connection_table = pyodbc.connect(cnxn_table)\n",
    "        print(\"successfully\") \n",
    "        # Connexion à la base de données\n",
    "        connection_table = pyodbc.connect(cnxn_table)\n",
    "\n",
    "        # Activation de l'autocommit pour valider automatiquement les transactions\n",
    "        connection_table.autocommit = True\n",
    "\n",
    "        # Création d'un curseur pour exécuter les commandes SQL\n",
    "        cursor = connection_table.cursor()\n",
    "        # Itération sur les lignes de la DataFrame et insertion de nouvelles lignes dans la table\n",
    "        for index, row in df.iterrows():\n",
    "            Profil = row['profile'] \n",
    "            Competences = row['competance']\n",
    "            Experiences_Professionnelles = row['experience_professionnelle']\n",
    "            Formation = row['formation']\n",
    "            Langues = row['langues']\n",
    "            Centre = row['centre']\n",
    "            Contact = row['Contact']\n",
    "            Phone_Number = row['phone number'] \n",
    "            Email = row['email']\n",
    "            LinkedIn = row['linkedin']\n",
    "            cursor.execute('SELECT CV_id FROM CV WHERE Profil = ?  AND Competences = ?', Profil, Competences)\n",
    "            CV_id = cursor.fetchone()\n",
    "            CV_id = cursor.execute('SELECT @@IDENTITY').fetchone()[0]\n",
    "            # Insertion d'une nouvelle ligne dans la table CV avec toutes les colonnes\n",
    "            cursor.execute('INSERT INTO CV (Profil, Competences, Experiences_Professionnelles, Formation, Langues, Centre, Contact, Phone_Number, Email, LinkedIn) '\n",
    "                'VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)',\n",
    "            (Profil, Competences, Experiences_Professionnelles, Formation, Langues, Centre, Contact, Phone_Number, Email, LinkedIn))\n",
    "        # Validation de la transaction et fermeture du curseur et de la connexion\n",
    "        connection_table.commit()\n",
    "        cursor.close()\n",
    "        connection_table.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d377401-d7a3-40e3-acdf-5b765d87852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 800x576 1 profile, 1 experience, 1 formation, 1 langues, 1 contact, 548.9ms\n",
      "Speed: 22.8ms preprocess, 548.9ms inference, 0.0ms postprocess per image at shape (1, 3, 800, 800)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/ASUS/code/src/content/output/content/output\\profile\\cv14_page-0001-0.jpg\n",
      "C:/Users/ASUS/code/src/content/output/content/output\\experience_professionnelle\\cv14_page-0001-2.jpg\n",
      "C:/Users/ASUS/code/src/content/output/content/output\\formation\\cv14_page-0001-3.jpg\n",
      "C:/Users/ASUS/code/src/content/output/content/output\\langues\\cv14_page-0001-4.jpg\n",
      "C:/Users/ASUS/code/src/content/output/content/output\\Contact\\cv14_page-0001-6.jpg\n",
      "                                             profile  competance  \\\n",
      "0  profil  actuellement, étudiant en 3eme année c...         NaN   \n",
      "\n",
      "                          experience_professionnelle  \\\n",
      "0  experiences professionnelles  stagiaire, arab ...   \n",
      "\n",
      "                                           formation  \\\n",
      "0  education  ingénierie en intelligence artifici...   \n",
      "\n",
      "                                             langues  centre  \\\n",
      "0  langues arabe francais anglais  allemand  dist...     NaN   \n",
      "\n",
      "                                             Contact  \n",
      "0  aloulou karim etudiant en ingénierie en ia  * ...  \n",
      "                                             profile  competance  \\\n",
      "0  profil  actuellement, étudiant en 3eme année c...         NaN   \n",
      "\n",
      "                          experience_professionnelle  \\\n",
      "0  experiences professionnelles  stagiaire, arab ...   \n",
      "\n",
      "                                           formation  \\\n",
      "0  education  ingénierie en intelligence artifici...   \n",
      "\n",
      "                             langues  centre  \\\n",
      "0  arab, francais, anglais, allemand     NaN   \n",
      "\n",
      "                                             Contact  \n",
      "0  aloulou karim etudiant en ingénierie en ia  * ...  \n",
      "Driver={ODBC Driver 17 for SQL Server};Server=ISLEM;Database=job_finder;Trusted_Connection=yes;\n",
      "successfully\n"
     ]
    }
   ],
   "source": [
    "analyzer = CVAnalyzer()\n",
    "# Load the YOLO model\n",
    "analyzer.load_yolo_model('C:/Users/ASUS/code/src/content/runs/content/runs/detect/train/weights/best.pt')\n",
    "results = analyzer.get_predictions('C:/Users/ASUS/code/src/content/datasets/content/datasets/train/images/cv14_page-0001.jpg', confidence=0.8)\n",
    "bboxes = results[0].boxes.xyxy  # les coordonnées des boîtes englobantes\n",
    "probs = results[0].boxes.conf  # les confiances des prédictions\n",
    "names = results[0].boxes.cls   # les classes des prédictions\n",
    "name = \"cv14_page-0001.jpg\"\n",
    "# Extract values from the image and get the dataframe\n",
    "df = analyzer.extract_values_from_image('C:/Users/ASUS/code/src/content/datasets/content/datasets/train/images/cv14_page-0001.jpg', 'C:/Users/ASUS/code/src/content/output/content/output', name, bboxes, probs, names)\n",
    "csv_file='my_dataframe.csv'\n",
    "df=analyzer.clean_and_sort_dataframe(csv_file)\n",
    "language_keywords = ['francais', 'anglais', 'allemand', 'espagnol', 'italien', 'arab']\n",
    "analyzer.extract_languages_from_dataframe(df,language_keywords)\n",
    "df = analyzer.extract_contact_info(df)  # Apply to the first row (index 0)\n",
    "analyzer.apply_extraction(df)\n",
    "new_df = analyzer.replace(df)\n",
    "analyzer.save_in_database(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1c6c33a-5872-452b-93b8-88984fda8afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile</th>\n",
       "      <th>competance</th>\n",
       "      <th>experience_professionnelle</th>\n",
       "      <th>formation</th>\n",
       "      <th>langues</th>\n",
       "      <th>centre</th>\n",
       "      <th>Contact</th>\n",
       "      <th>phone number</th>\n",
       "      <th>email</th>\n",
       "      <th>linkedin</th>\n",
       "      <th>extracted_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>profil  actuellement, étudiant en 3eme année c...</td>\n",
       "      <td>None</td>\n",
       "      <td>experiences professionnelles  stagiaire, arab ...</td>\n",
       "      <td>education  ingénierie en intelligence artifici...</td>\n",
       "      <td>arab, francais, anglais, allemand</td>\n",
       "      <td>None</td>\n",
       "      <td>aloulou karim etudiant en ingénierie en ia  * ...</td>\n",
       "      <td>20107299</td>\n",
       "      <td>karim.aloulou@esprit.tn</td>\n",
       "      <td>linkedin.com/in/karim-aloulou-</td>\n",
       "      <td>profil  actuellement, étudiant en 3eme année c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             profile competance  \\\n",
       "0  profil  actuellement, étudiant en 3eme année c...       None   \n",
       "\n",
       "                          experience_professionnelle  \\\n",
       "0  experiences professionnelles  stagiaire, arab ...   \n",
       "\n",
       "                                           formation  \\\n",
       "0  education  ingénierie en intelligence artifici...   \n",
       "\n",
       "                             langues centre  \\\n",
       "0  arab, francais, anglais, allemand   None   \n",
       "\n",
       "                                             Contact phone number  \\\n",
       "0  aloulou karim etudiant en ingénierie en ia  * ...     20107299   \n",
       "\n",
       "                     email                        linkedin  \\\n",
       "0  karim.aloulou@esprit.tn  linkedin.com/in/karim-aloulou-   \n",
       "\n",
       "                                   extracted_profile  \n",
       "0  profil  actuellement, étudiant en 3eme année c...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562845a4-374d-4a4c-9bbe-072a552b6c84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea41e1f2-b5d5-48ad-b3c7-232a8ea05fea",
   "metadata": {},
   "source": [
    "<span style=\"color:DarkKhaki; font-size:30px\">**CV_Analyser**</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3e3d90-2434-44e2-a61e-e7666bc06924",
   "metadata": {},
   "source": [
    "<span style= \"color:RosyBrown;font-size:20px\">**1-Extraction des differentes parties du cv**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f23ecc-9c21-485b-9f3f-329ffaae9a0d",
   "metadata": {},
   "source": [
    "<span style= \"color:PaleVioletRed; font-size:16px\">**1er Méthode:NLP**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7245aad1-2128-45af-a8e7-943761d26865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from PyPDF2) (4.5.0)\n",
      "Requirement already satisfied: textract in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.6.5)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\asus\\anaconda3\\lib\\site-packages (from textract) (3.0.4)\n",
      "Requirement already satisfied: extract-msg<=0.29.* in c:\\users\\asus\\anaconda3\\lib\\site-packages (from textract) (0.28.7)\n",
      "Requirement already satisfied: argcomplete~=1.10.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from textract) (1.10.3)\n",
      "Requirement already satisfied: six~=1.12.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from textract) (1.12.0)\n",
      "Requirement already satisfied: xlrd~=1.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from textract) (1.2.0)\n",
      "Requirement already satisfied: python-pptx~=0.6.18 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from textract) (0.6.21)\n",
      "Requirement already satisfied: docx2txt~=0.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from textract) (0.8)\n",
      "Requirement already satisfied: SpeechRecognition~=3.8.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from textract) (3.8.1)\n",
      "Requirement already satisfied: beautifulsoup4~=4.8.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from textract) (4.8.2)\n",
      "Collecting pdfminer.six==20191110\n",
      "  Using cached pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: pycryptodome in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pdfminer.six==20191110->textract) (3.17)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from beautifulsoup4~=4.8.0->textract) (2.2.1)\n",
      "Requirement already satisfied: compressed-rtf>=1.0.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from extract-msg<=0.29.*->textract) (1.0.6)\n",
      "Requirement already satisfied: tzlocal>=2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from extract-msg<=0.29.*->textract) (4.2)\n",
      "Requirement already satisfied: ebcdic>=1.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from extract-msg<=0.29.*->textract) (1.1.1)\n",
      "Requirement already satisfied: imapclient==2.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from extract-msg<=0.29.*->textract) (2.1.0)\n",
      "Requirement already satisfied: olefile>=0.46 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from extract-msg<=0.29.*->textract) (0.46)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-pptx~=0.6.18->textract) (9.4.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-pptx~=0.6.18->textract) (3.0.1)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-pptx~=0.6.18->textract) (4.6.3)\n",
      "Requirement already satisfied: pytz-deprecation-shim in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tzlocal>=2.1->extract-msg<=0.29.*->textract) (0.1.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tzlocal>=2.1->extract-msg<=0.29.*->textract) (2022.7)\n",
      "Installing collected packages: pdfminer.six\n",
      "  Attempting uninstall: pdfminer.six\n",
      "    Found existing installation: pdfminer.six 20221105\n",
      "    Uninstalling pdfminer.six-20221105:\n",
      "      Successfully uninstalled pdfminer.six-20221105\n",
      "Successfully installed pdfminer.six-20191110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pdfplumber 0.8.0 requires pdfminer.six==20221105, but you have pdfminer-six 20191110 which is incompatible.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "textract 1.6.5 requires pdfminer.six==20191110, but you have pdfminer-six 20221105 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pdfplumber) (9.4.0)\n",
      "Requirement already satisfied: Wand>=0.6.10 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pdfplumber) (0.6.11)\n",
      "Collecting pdfminer.six==20221105\n",
      "  Using cached pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pdfminer.six==20221105->pdfplumber) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pdfminer.six==20221105->pdfplumber) (40.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.20)\n",
      "Installing collected packages: pdfminer.six\n",
      "  Attempting uninstall: pdfminer.six\n",
      "    Found existing installation: pdfminer.six 20191110\n",
      "    Uninstalling pdfminer.six-20191110:\n",
      "      Successfully uninstalled pdfminer.six-20191110\n",
      "Successfully installed pdfminer.six-20221105\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2\n",
    "!pip install textract\n",
    "!pip install pdfplumber\n",
    "import PyPDF2, pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e581d23f-714b-44cd-b0a2-04f3b35b38a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profil</th>\n",
       "      <th>Expériences Professionnelles</th>\n",
       "      <th>Contact</th>\n",
       "      <th>Compétences</th>\n",
       "      <th>Formation</th>\n",
       "      <th>Langues</th>\n",
       "      <th>Centres d’Intérêt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Commercial diplômé, j’ai une expérience de 3 a...</td>\n",
       "      <td>Commercial DIOR, Paris | 2019 – 2022 •  Prospe...</td>\n",
       "      <td>06 06 06 06 06 raphael.martin@gnail.com Paris,...</td>\n",
       "      <td>•  Sens du contact •  Communication  •  Capaci...</td>\n",
       "      <td>Licence Pro Commerce et Distribution Universit...</td>\n",
       "      <td>Français   Anglais   Espagnol</td>\n",
       "      <td>•  Triathlon •  Randonnée •  Bénévolat •  Voya...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Profil  \\\n",
       "0  Commercial diplômé, j’ai une expérience de 3 a...   \n",
       "\n",
       "                        Expériences Professionnelles  \\\n",
       "0  Commercial DIOR, Paris | 2019 – 2022 •  Prospe...   \n",
       "\n",
       "                                             Contact  \\\n",
       "0  06 06 06 06 06 raphael.martin@gnail.com Paris,...   \n",
       "\n",
       "                                         Compétences  \\\n",
       "0  •  Sens du contact •  Communication  •  Capaci...   \n",
       "\n",
       "                                           Formation  \\\n",
       "0  Licence Pro Commerce et Distribution Universit...   \n",
       "\n",
       "                         Langues  \\\n",
       "0  Français   Anglais   Espagnol   \n",
       "\n",
       "                                   Centres d’Intérêt  \n",
       "0  •  Triathlon •  Randonnée •  Bénévolat •  Voya...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import pdfminer\n",
    "import re\n",
    "import pandas as pd\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "# Specify the path to the CV file as a string\n",
    "cv_path = 'cv.pdf'\n",
    "\n",
    "# Set up the DataFrame columns\n",
    "columns = ['Profil','Expériences Professionnelles','Formation', 'Contact','Compétences' , 'Langues', 'Centres d’Intérêt']\n",
    "\n",
    "# Create an empty DataFrame with the specified columns\n",
    "cv_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Open the CV file in binary read mode\n",
    "with open(cv_path, 'rb') as cv_file:\n",
    "    # Set up the PDF document and resource manager objects\n",
    "    resource_manager = PDFResourceManager()\n",
    "    output_stream = io.StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = pdfminer.layout.LAParams()\n",
    "    device = TextConverter(resource_manager, output_stream, codec=codec, laparams=laparams)\n",
    "    # Set up the PDF interpreter object\n",
    "    interpreter = PDFPageInterpreter(resource_manager, device)\n",
    "    # Iterate over each page of the PDF file\n",
    "    for page in PDFPage.get_pages(cv_file):\n",
    "        interpreter.process_page(page)\n",
    "    # Get the extracted text\n",
    "    cv_text = output_stream.getvalue()\n",
    "# Close the TextConverter object\n",
    "device.close()\n",
    "cv_text=''.join(cv_text)\n",
    "cv_text=cv_text.replace(\"\\n\",\"\")\n",
    "# Extract the information using regular expressions\n",
    "profil = re.search(r'PROFIL(.+?)(EXPERIENCES PROFESSIONNELLES|COMPÉTENCES|FORMATION|LANGUES|CENTRES D’INTÉRÊT)', cv_text, re.DOTALL)\n",
    "if profil:\n",
    "    profil = profil.group(1).strip()\n",
    "else:\n",
    "    profil = ''\n",
    "    \n",
    "experiences_pro = re.search(r'EXPERIENCES PROFESSIONNELLES(.+?)(COMPÉTENCES|FORMATION|LANGUES|CENTRES D’INTÉRÊT)', cv_text, re.DOTALL)\n",
    "if experiences_pro:\n",
    "    experiences_pro = experiences_pro.group(1).strip()\n",
    "else:\n",
    "    experiences_pro = ''\n",
    "    \n",
    "formation = re.search(r'FORMATION(.+?)(LANGUES|CENTRES D’INTÉRÊT)', cv_text, re.DOTALL)\n",
    "if formation:\n",
    "    formation = formation.group(1).strip()\n",
    "else:\n",
    "    formation = ''\n",
    "\n",
    "contact = re.search(r'CONTACT(.+?)(COMPÉTENCES|FORMATION|LANGUES|CENTRES D’INTÉRÊT)', cv_text, re.DOTALL)\n",
    "if contact:\n",
    "    contact = contact.group(1).strip()\n",
    "else:\n",
    "    contact = ''\n",
    "    \n",
    "competences = re.search(r'COMPÉTENCES(.+?)(FORMATION|LANGUES|CENTRES D’INTÉRÊT)', cv_text, re.DOTALL)\n",
    "if competences:\n",
    "    competences = competences.group(1).strip()\n",
    "else:\n",
    "    competences = ''\n",
    "langues = re.search(r'LANGUES(.+?)(CENTRES D’INTÉRÊT|COMPÉTENCES)', cv_text, re.DOTALL)\n",
    "if langues:\n",
    "    langues = langues.group(1).strip()\n",
    "else:\n",
    "    langues = ''\n",
    "\n",
    "centres_interet = re.search(r'CENTRES D’INTÉRÊT(.+)', cv_text, re.DOTALL)\n",
    "if centres_interet:\n",
    "    centres_interet = centres_interet.group(1).strip()\n",
    "else:\n",
    "    centres_interet = ''\n",
    "\n",
    "# Fill the DataFrame with the extracted information\n",
    "cv_df = pd.DataFrame({'Profil': [profil],'Expériences Professionnelles': [experiences_pro], 'Contact': [contact], 'Compétences': [competences], 'Formation': [formation],'Langues': [langues],'Centres d’Intérêt': [centres_interet]})\n",
    "\n",
    "# Print the DataFrame\n",
    "#print(cv_df)\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87796508-f229-49c5-9fc7-abd2a58d97be",
   "metadata": {},
   "source": [
    "<span style=\"color:RosyBrown;font-size:20px\">**Prétraitement des donnés**</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53991d25-a965-43b4-a01e-0767db4a34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db1739c-ce09-4926-abd3-d947b5b1e62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f043f70-474e-494f-9d8f-5e0fec3453b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '', 'phone': '06 06 06 06 06', 'email': 'raphael.martin@gnail.com', 'adress': 'Paris, France'}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "def extract_name_and_contact(text):\n",
    "    doc = nlp(text)\n",
    "    name = \"\"\n",
    "    phone = \"\"\n",
    "    email = \"\"\n",
    "    name_regex = r\"(Mme|Mr|Dr)\\.?\\s+(\\b[A-Z][a-z]+\\b\\s+[A-Z][a-z]+\\b)\"\n",
    "    name_matches = re.findall(name_regex, text)\n",
    "    if name_matches:\n",
    "        for match in name_matches:\n",
    "            if any([ent.text == match for ent in doc.ents if ent.label_ == \"PER\"]):\n",
    "                name = match\n",
    "                break\n",
    "    phone_regex = r\"(?:\\+33|0)\\s*[1-9](?:[\\s.-]*\\d{2}){4}\"\n",
    "    phone_match = re.search(phone_regex, text)\n",
    "    if phone_match:\n",
    "        phone = phone_match.group(0)\n",
    "    email_regex = r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'\n",
    "   # email_regex = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
    "    email_match = re.search(email_regex, text)\n",
    "    if email_match:\n",
    "        email = email_match.group(0)\n",
    "    address_pattern = r'([A-Z][a-z]+,\\s[A-Z][a-z]+)'\n",
    "    address_match = re.search(address_pattern, text)\n",
    "    if address_match:\n",
    "        adress = address_match.group(0)\n",
    "   \n",
    "    return {\"name\": name, \"phone\": phone, \"email\": email, \"adress\": adress }\n",
    "\n",
    "info = extract_name_and_contact(cv_df['Contact'][0]) \n",
    "print(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6845c502-c479-469a-8e1a-129954f0fb65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Commercial DIOR, Paris | 2019 – 2022   Prospection commercial et gestion d’un portefeuille client.   Développement de nouveaux produits et projets innovants.   Garantir le bon déroulement des formations, aussi bien à leur démarrage qu’à leur aboutissement.   Participer au développement de marque via l’organisation de la communication et d’évènements locaux.  Assistant Commercial Export ORANGE, Paris | 2016-2019   Assurer la mise à jour des coordonnées administrative relatives au compte client.   Traiter les demandes d’échantillon depuis la saisie jusqu’à l’expédition.   Assurer l'interface entreprise-client export pour tout service sollicité. Assistant Commercial Stagiaire DANONE, Paris | 2015    Etablir des documents nécessaires à l'expédition des commandes en fonction de son pays de destination, de l’incoterm ainsi que du mode de règlement convenu.   Assurer l'accueil téléphonique des clients, fournisseurs et autres tiers.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df['Expériences Professionnelles'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d0dcf4-877b-458f-a78f-36d5dbbe9c67",
   "metadata": {},
   "source": [
    "**Définir le nombre d'année d'expérience**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bb5754c-aabf-45c4-ba2d-6204e27fd354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Profil  \\\n",
      "0  Commercial diplômé, j’ai une expérience de 3 a...   \n",
      "\n",
      "                        Expériences Professionnelles  \\\n",
      "0  Commercial DIOR, Paris | 2019 – 2022 •  Prospe...   \n",
      "\n",
      "                                             Contact  \\\n",
      "0  06 06 06 06 06 raphael.martin@gnail.com Paris,...   \n",
      "\n",
      "                                         Compétences  \\\n",
      "0  •  Sens du contact •  Communication  •  Capaci...   \n",
      "\n",
      "                                           Formation  \\\n",
      "0  Licence Pro Commerce et Distribution Universit...   \n",
      "\n",
      "                         Langues  \\\n",
      "0  Français   Anglais   Espagnol   \n",
      "\n",
      "                                   Centres d’Intérêt Nb d'années d'expérience  \n",
      "0  •  Triathlon •  Randonnée •  Bénévolat •  Voya...                        3  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "# Définir une expression régulière pour extraire le nombre d'années d'expérience\n",
    "pattern = r'(\\d+)\\s+ans'\n",
    "\n",
    "# Appliquer l'expression régulière à la colonne \"Profil\" pour extraire le nombre d'années d'expérience\n",
    "cv_df['Nb d\\'années d\\'expérience'] = cv_df['Profil'].apply(lambda x: re.findall(pattern, x)[0])\n",
    "\n",
    "# Afficher le dataframe avec la nouvelle colonne \"Nb d'années d'expérience\"\n",
    "print(cv_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db773559-2b77-4070-95cd-1759c3d47252",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = cv_df.replace('\\n\\n•', '', regex=True).replace('\\n', ' ', regex=True).replace('•','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e9369e6-1f60-41d1-85f6-46cc51203c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profil</th>\n",
       "      <th>Expériences Professionnelles</th>\n",
       "      <th>Contact</th>\n",
       "      <th>Compétences</th>\n",
       "      <th>Formation</th>\n",
       "      <th>Langues</th>\n",
       "      <th>Centres d’Intérêt</th>\n",
       "      <th>Nb d'années d'expérience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Commercial diplômé, j’ai une expérience de 3 a...</td>\n",
       "      <td>Commercial DIOR, Paris | 2019 – 2022   Prospec...</td>\n",
       "      <td>06 06 06 06 06 raphael.martin@gnail.com Paris,...</td>\n",
       "      <td>Sens du contact   Communication    Capacité ...</td>\n",
       "      <td>Licence Pro Commerce et Distribution Universit...</td>\n",
       "      <td>Français   Anglais   Espagnol</td>\n",
       "      <td>Triathlon   Randonnée   Bénévolat   Voyage e...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Profil  \\\n",
       "0  Commercial diplômé, j’ai une expérience de 3 a...   \n",
       "\n",
       "                        Expériences Professionnelles  \\\n",
       "0  Commercial DIOR, Paris | 2019 – 2022   Prospec...   \n",
       "\n",
       "                                             Contact  \\\n",
       "0  06 06 06 06 06 raphael.martin@gnail.com Paris,...   \n",
       "\n",
       "                                         Compétences  \\\n",
       "0    Sens du contact   Communication    Capacité ...   \n",
       "\n",
       "                                           Formation  \\\n",
       "0  Licence Pro Commerce et Distribution Universit...   \n",
       "\n",
       "                         Langues  \\\n",
       "0  Français   Anglais   Espagnol   \n",
       "\n",
       "                                   Centres d’Intérêt Nb d'années d'expérience  \n",
       "0    Triathlon   Randonnée   Bénévolat   Voyage e...                        3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cde7627c-72f7-4d01-9e09-93d8f430d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assuming you have already created your DataFrame cv_df\n",
    "# save DataFrame to a CSV file\n",
    "cv_df.to_csv('my_cv_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057777f6-68f7-4213-8685-4cc1712be677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae3a1b8-2513-4755-914c-b273bcea89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def identifier_sections_cv(cv_text):\n",
    "    # Diviser le texte en phrases\n",
    "    phrases = re.split('[.?!]', cv_text)\n",
    "    # Liste de mots clés pour chaque section du CV\n",
    "    mots_cles = {\n",
    "        'formation': ['formation', 'diplôme', 'études', 'certification'],\n",
    "        'experience': ['expérience', 'professionnelle', 'stage', 'emploi'],\n",
    "        'competences': ['compétences', 'connaissances', 'aptitudes'],\n",
    "        'langues': ['langues', 'niveau', 'linguistique'],\n",
    "        'interets': ['intérêts', 'loisirs', 'hobbies']\n",
    "    }\n",
    "    # Dictionnaire pour stocker les phrases associées à chaque section\n",
    "    sections = {\n",
    "        'formation': [],\n",
    "        'experience': [],\n",
    "        'competences': [],\n",
    "        'langues': [],\n",
    "        'interets': []\n",
    "    }\n",
    "    # Parcourir chaque phrase et la classifier dans la section appropriée\n",
    "    for phrase in phrases:\n",
    "        for section, mots in mots_cles.items():\n",
    "            for mot in mots:\n",
    "                if mot.lower() in phrase.lower():\n",
    "                    sections[section].append(phrase.strip())\n",
    "                    break\n",
    "    # Supprimer les sections vides\n",
    "    sections = {section: phrases for section, phrases in sections.items() if phrases}\n",
    "    # Retourner les sections identifiées\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc733c8-a44c-46f3-b04a-994f2a8a1db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extraire_info_cv(cv_text):\n",
    "    # Extraire le nom\n",
    "    nom = re.search(r'\\b[A-Z][a-z]*\\s[A-Z][a-z]*\\b', cv_text)\n",
    "    nom = nom.group(0) if nom else None\n",
    "\n",
    "    # Extraire l'adresse\n",
    "    adresse = re.search(r'\\b\\d{1,4}\\s\\w+\\s\\w+\\b', cv_text)\n",
    "    adresse = adresse.group(0) if adresse else None\n",
    "\n",
    "    # Extraire le mail\n",
    "    mail = re.search(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', cv_text)\n",
    "    mail = mail.group(0) if mail else None\n",
    "\n",
    "    # Stocker les résultats dans une dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'Nom': [nom],\n",
    "        'Adresse': [adresse],\n",
    "        'Email': [mail]\n",
    "    })\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53478188-7925-43ac-916f-6542b74df231",
   "metadata": {},
   "source": [
    "**Translation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ee4fb-28f4-40ac-bcfd-6019268dd612",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deep_translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e2fc76-7e53-4210-85fb-40927439ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langdetect googletrans==4.0.0-rc1\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "from googletrans import Translator\n",
    "\n",
    "# fonction pour traduire chaque élément de la colonne texte\n",
    "def translate_text(text):\n",
    "    return GoogleTranslator(source='auto', target='fr').translate(text)\n",
    "\n",
    "# appliquer la fonction de traduction à la colonne texte\n",
    "cv_df['Profil'] = cv_df['Profil'].apply(translate_text)\n",
    "cv_df['Compétences'] = cv_df['Compétences'].apply(translate_text)\n",
    "cv_df['Formation'] = cv_df['Formation'].apply(translate_text)\n",
    "cv_df['Centres d’Intérêt'] = cv_df['Centres d’Intérêt'].apply(translate_text)\n",
    "# Print the translated DataFrame\n",
    "cv_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af758927-1dee-4186-a8f0-51572588d7e5",
   "metadata": {},
   "source": [
    "<span style= \"color:RosyBrown;font-size:20px\">**Save into database**</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c79951f5-91a8-4b58-a9b0-68221f122951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver={ODBC Driver 17 for SQL Server};Server=ISLEM;Database=job_finder;Trusted_Connection=yes;\n",
      "successfully\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import configparser\n",
    "# Load the config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "cnxn_table = (\n",
    "    \"Driver={\"+config['Database']['Driver']+\"};\"\n",
    "    \"Server=\"+config['Database']['Server']+\";\"\n",
    "    \"Database=\"+config['Database']['Database']+\";\"\n",
    "    \"Trusted_Connection=\"+config['Database']['Trusted_Connection']+\";\")\n",
    "print(cnxn_table)\n",
    "# Establish a database connection\n",
    "connection_table = pyodbc.connect(cnxn_table)\n",
    "print(\"successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a368219a-fa0c-4761-abb0-9e0fc95891c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_table.autocommit = True\n",
    "# Create a cursor object to execute SQL commands\n",
    "cursor = connection_table.cursor()\n",
    "cursor.execute('CREATE TABLE CV( CV_id INT IDENTITY(1,1) PRIMARY KEY, offre_demploi_id INT FOREIGN KEY REFERENCES Offre_demploi(id_offre_demploi), Profil NVARCHAR(max), Experiences_Professionnelles NVARCHAR(max), Contact NVARCHAR(max), Compétences NVARCHAR(max), Formation NVARCHAR(max), Langues NVARCHAR(max), Centres_dInteret NVARCHAR(max), Nb_dannees_experience INT, Numero_de_telephone NVARCHAR(20), E_mail NVARCHAR(50), Adresse NVARCHAR(255), Profil_LinkedIn NVARCHAR(255), CV_text NVARCHAR(max))')\n",
    "# Iterate over the rows of the dataframe and insert new rows into the table\n",
    "for index, row in cv_df.iterrows():\n",
    "    Profil = row['Profil']\n",
    "    Compétences = row['Compétences']\n",
    "    #Expériences Professionnelles = row['Expériences Professionnelles']\n",
    "    Formation = row['Formation']\n",
    "    Langues = row['Langues']\n",
    "    Contact = row['Contact']\n",
    "\n",
    "    # Insert a new row into the entreprise table\n",
    "    cursor.execute('INSERT INTO CV (Profil, Compétences, Formation, Langues, Contact ) VALUES (?, ?, ?, ?, ?)', (Profil, Compétences, Formation, Langues, Contact))\n",
    "\n",
    "# Commit the transaction and close the cursor and connection\n",
    "connection_table.commit()\n",
    "cursor.close()\n",
    "connection_table.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9717991-59c6-4745-8e9c-4cd192acabe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set autocommit to True to automatically commit changes to the database\n",
    "connection_table.autocommit = True\n",
    "\n",
    "# Create a cursor object to execute SQL commands\n",
    "cursor = connection_table.cursor()\n",
    "\n",
    "# Iterate over the rows of the dataframe and insert new rows into the table\n",
    "for index, row in preprocessed_df.iterrows():\n",
    "    profil = row['profil']\n",
    "    Mail = row['Mail']\n",
    "    nom = row['nom']\n",
    "    Prénom = row['Prénom']\n",
    "    Date de naissance = row['Date de naissance']\n",
    "    Compétances = row['Compétances']\n",
    "    Experiences = row['Experiences']\n",
    "    Formation = row['Formation']\n",
    "    Langues = row['Langues']\n",
    "    Centres dinteret = row['Centres dinteret']\n",
    "    contact = row['contact']\n",
    "    \n",
    "    # Check if the entreprise already exists in the database\n",
    "    cursor.execute('SELECT id_entreprise FROM Entreprise WHERE company_name = ?', company_name)\n",
    "    existing_entreprise_id = cursor.fetchone()\n",
    "    \n",
    "    if existing_entreprise_id:\n",
    "        # If the entreprise already exists, use its ID\n",
    "        entreprise_id = existing_entreprise_id[0]\n",
    "    else:\n",
    "        # If the entreprise does not exist, insert a new row and retrieve its ID\n",
    "        cursor.execute('INSERT INTO Entreprise (company_name, company_location, presentation_entreprise) VALUES (?, ?, ?)', company_name, company_location, presentation_entreprise)\n",
    "        entreprise_id = cursor.execute('SELECT @@IDENTITY').fetchone()[0]\n",
    "    \n",
    "    # Check if the offre_demploi already exists in the database\n",
    "    cursor.execute('SELECT id_offre_demploi FROM Offre_demploi WHERE job_title = ?  AND post_date = ?', job_title, post_date)\n",
    "    existing_offre_demploi_id = cursor.fetchone()\n",
    "    \n",
    "    if existing_offre_demploi_id:\n",
    "        # If the offre_demploi already exists, use its ID\n",
    "        offre_demploi_id = existing_offre_demploi_id[0]\n",
    "    else:\n",
    "         # Insert a new row into the entreprise table\n",
    "        cursor.execute('INSERT INTO Entreprise (company_name, company_location, presentation_entreprise) VALUES (?, ?, ?)', company_name, company_location, presentation_entreprise)\n",
    "        # Insert a new row into the offre_demploi table using the retrieved id value\n",
    "        id_entreprise = cursor.execute('SELECT @@IDENTITY').fetchone()[0]\n",
    "        #cursor.execute('INSERT INTO Offre_demploi (job_title, work_method, post_date, work_time, job_description, competence_part, job_experience) VALUES (?, ?, ?, ?, ?, ?, ?)', job_title, work_method, post_date, work_time, job_description, competence_part, job_experience)\n",
    "        cursor.execute('INSERT INTO Offre_demploi ( job_title, work_method, post_date, work_time, job_description, competence_part, job_experience) VALUES (?, ?, ?, ?, ?, ?, ?)', job_title, work_method, post_date, work_time, job_description, competence_part,job_experience)\n",
    "        offre_demploi_id = cursor.execute('SELECT @@IDENTITY').fetchone()[0]\n",
    "        cursor.execute('INSERT INTO Entreprise_offre_demploi (id_entreprise, offre_demploi_id) VALUES (?,?)', id_entreprise, offre_demploi_id)\n",
    "# Commit the transaction and close the cursor and connection\n",
    "connection_table.commit()\n",
    "cursor.close()\n",
    "connection_table.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
